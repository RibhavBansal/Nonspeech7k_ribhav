{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7755082,"sourceType":"datasetVersion","datasetId":4534603},{"sourceId":7755430,"sourceType":"datasetVersion","datasetId":4534861},{"sourceId":7819374,"sourceType":"datasetVersion","datasetId":4536124}],"dockerImageVersionId":29926,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  <center> Speech Recognition <center>","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"!apt update\n!apt-get install -y libsndfile1","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:32:01.408356Z","iopub.execute_input":"2024-03-11T14:32:01.40904Z","iopub.status.idle":"2024-03-11T14:32:15.754636Z","shell.execute_reply.started":"2024-03-11T14:32:01.408989Z","shell.execute_reply":"2024-03-11T14:32:15.75331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\n# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\n# to play the audio files\nfrom IPython.display import Audio\n\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import GRU, LSTM, TimeDistributed\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint\n\nimport tensorflow as tf\n\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-03-11T14:33:44.779172Z","iopub.execute_input":"2024-03-11T14:33:44.77966Z","iopub.status.idle":"2024-03-11T14:33:54.504722Z","shell.execute_reply.started":"2024-03-11T14:33:44.779616Z","shell.execute_reply":"2024-03-11T14:33:54.503087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"##  <center> 1. NonSpeech7k dataset <center>","metadata":{}},{"cell_type":"code","source":"# Paths for data.\nNonspeech7k_test_data = pd.read_csv(\"/kaggle/input/nonspeech7k/metadata of test set.csv\")\nNonspeech7k_train_data = pd.read_csv(\"/kaggle/input/nonspeech7k/metadata of train set .csv\")\nNonspeech7k_audio_data1 = \"/kaggle/input/nonspeech7k-audio\"\nNonspeech7k_audio_data2 = \"/kaggle/input/nonspeech7k-audio-train/train - Copy/train - Copy/train\"","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:54.509093Z","iopub.execute_input":"2024-03-11T14:33:54.509744Z","iopub.status.idle":"2024-03-11T14:33:54.581793Z","shell.execute_reply.started":"2024-03-11T14:33:54.509687Z","shell.execute_reply":"2024-03-11T14:33:54.579951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Nonspeech7k_train_data","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:54.584252Z","iopub.execute_input":"2024-03-11T14:33:54.585166Z","iopub.status.idle":"2024-03-11T14:33:54.642694Z","shell.execute_reply.started":"2024-03-11T14:33:54.5851Z","shell.execute_reply":"2024-03-11T14:33:54.640645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Nonspeech7k_test_data","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:54.644913Z","iopub.execute_input":"2024-03-11T14:33:54.645357Z","iopub.status.idle":"2024-03-11T14:33:54.680469Z","shell.execute_reply.started":"2024-03-11T14:33:54.645318Z","shell.execute_reply":"2024-03-11T14:33:54.678772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"element = Nonspeech7k_test_data.loc[3, \"Classname\"]\nelement","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:54.687263Z","iopub.execute_input":"2024-03-11T14:33:54.687703Z","iopub.status.idle":"2024-03-11T14:33:54.706253Z","shell.execute_reply.started":"2024-03-11T14:33:54.687665Z","shell.execute_reply":"2024-03-11T14:33:54.704113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = Nonspeech7k_test_data[Nonspeech7k_test_data['Filename']==\"112557-2_0_0.wav\"] \ndata[\"Classname\"].values[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:54.71204Z","iopub.execute_input":"2024-03-11T14:33:54.712531Z","iopub.status.idle":"2024-03-11T14:33:54.729477Z","shell.execute_reply.started":"2024-03-11T14:33:54.71249Z","shell.execute_reply":"2024-03-11T14:33:54.727829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nonspeech7k_directory_list = os.listdir(Nonspeech7k_audio_data2)\n\nfile_emotion = []\nfile_path = []\n\nfor i,file in enumerate(nonspeech7k_directory_list):\n    # storing file paths\n    file_path.append(Nonspeech7k_audio_data2 + '/' + file)\n    # storing file emotions\n    data = Nonspeech7k_train_data[Nonspeech7k_train_data['Filename']==file] \n    file_emotion.append(data[\"Classname\"].values[0])\n    \n        \n# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n\n# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['Path'])\nNonspeech7k_df1 = pd.concat([emotion_df, path_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:54.732528Z","iopub.execute_input":"2024-03-11T14:33:54.733914Z","iopub.status.idle":"2024-03-11T14:33:58.421103Z","shell.execute_reply.started":"2024-03-11T14:33:54.733825Z","shell.execute_reply":"2024-03-11T14:33:58.419698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nonspeech7k_directory_list = os.listdir(Nonspeech7k_audio_data1)\n\nfile_emotion = []\nfile_path = []\n\nfor i,file in enumerate(nonspeech7k_directory_list):\n    # storing file paths\n    file_path.append(Nonspeech7k_audio_data1 + '/' + file)\n    # storing file emotions\n    data = Nonspeech7k_test_data[Nonspeech7k_test_data['Filename']==file] \n    file_emotion.append(data[\"Classname\"].values[0])\n    \n        \n# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n\n# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['Path'])\nNonspeech7k_df2 = pd.concat([emotion_df, path_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:58.422514Z","iopub.execute_input":"2024-03-11T14:33:58.422866Z","iopub.status.idle":"2024-03-11T14:33:59.522964Z","shell.execute_reply.started":"2024-03-11T14:33:58.42283Z","shell.execute_reply":"2024-03-11T14:33:59.521598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Nonspeech7k_df1","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:59.524719Z","iopub.execute_input":"2024-03-11T14:33:59.525197Z","iopub.status.idle":"2024-03-11T14:33:59.544479Z","shell.execute_reply.started":"2024-03-11T14:33:59.525146Z","shell.execute_reply":"2024-03-11T14:33:59.542827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Nonspeech7k_df2","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:59.54709Z","iopub.execute_input":"2024-03-11T14:33:59.547764Z","iopub.status.idle":"2024-03-11T14:33:59.566878Z","shell.execute_reply.started":"2024-03-11T14:33:59.54772Z","shell.execute_reply":"2024-03-11T14:33:59.565311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nonspeech7k_df = pd.concat([Nonspeech7k_df1,Nonspeech7k_df2],axis = 0)\n# Nonspeech7k_df.to_csv(\"Nonspeech7k_df.csv\",index=False)\nNonspeech7k_df = Nonspeech7k_df1\nNonspeech7k_df","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:59.570049Z","iopub.execute_input":"2024-03-11T14:33:59.570559Z","iopub.status.idle":"2024-03-11T14:33:59.594344Z","shell.execute_reply.started":"2024-03-11T14:33:59.570516Z","shell.execute_reply":"2024-03-11T14:33:59.593348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualisation and Exploration","metadata":{}},{"cell_type":"markdown","source":"First let's plot the count of each emotions in our dataset.","metadata":{}},{"cell_type":"code","source":"plt.title('Count of Emotions', size=16)\nsns.countplot(Nonspeech7k_df.Emotions)\nplt.ylabel('Count', size=12)\nplt.xlabel('Emotions', size=12)\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:59.595819Z","iopub.execute_input":"2024-03-11T14:33:59.59639Z","iopub.status.idle":"2024-03-11T14:33:59.891286Z","shell.execute_reply.started":"2024-03-11T14:33:59.596321Z","shell.execute_reply":"2024-03-11T14:33:59.889704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_waveplot(data, sr, e):\n    plt.figure(figsize=(10, 3))\n    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n    librosa.display.waveplot(data, sr=sr)\n    plt.show()\n\ndef create_spectrogram(data, sr, e):\n    # stft function converts the data into short term fourier transform\n    X = librosa.stft(data)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize=(12, 3))\n    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n    plt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:59.893119Z","iopub.execute_input":"2024-03-11T14:33:59.89349Z","iopub.status.idle":"2024-03-11T14:33:59.906026Z","shell.execute_reply.started":"2024-03-11T14:33:59.893453Z","shell.execute_reply":"2024-03-11T14:33:59.904292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion='laugh'\npath = np.array(Nonspeech7k_df.Path[Nonspeech7k_df.Emotions==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:33:59.907878Z","iopub.execute_input":"2024-03-11T14:33:59.908273Z","iopub.status.idle":"2024-03-11T14:34:01.823703Z","shell.execute_reply.started":"2024-03-11T14:33:59.908237Z","shell.execute_reply":"2024-03-11T14:34:01.822051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion='cough'\npath = np.array(Nonspeech7k_df.Path[Nonspeech7k_df.Emotions==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:01.825584Z","iopub.execute_input":"2024-03-11T14:34:01.826039Z","iopub.status.idle":"2024-03-11T14:34:02.557196Z","shell.execute_reply.started":"2024-03-11T14:34:01.825994Z","shell.execute_reply":"2024-03-11T14:34:02.555575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion='sneeze'\npath = np.array(Nonspeech7k_df.Path[Nonspeech7k_df.Emotions==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:02.558998Z","iopub.execute_input":"2024-03-11T14:34:02.559417Z","iopub.status.idle":"2024-03-11T14:34:03.307948Z","shell.execute_reply.started":"2024-03-11T14:34:02.559378Z","shell.execute_reply":"2024-03-11T14:34:03.306555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion='yawn'\npath = np.array(Nonspeech7k_df.Path[Nonspeech7k_df.Emotions==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:03.309599Z","iopub.execute_input":"2024-03-11T14:34:03.310004Z","iopub.status.idle":"2024-03-11T14:34:04.094365Z","shell.execute_reply.started":"2024-03-11T14:34:03.309962Z","shell.execute_reply":"2024-03-11T14:34:04.093054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion='crying'\npath = np.array(Nonspeech7k_df.Path[Nonspeech7k_df.Emotions==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:04.096222Z","iopub.execute_input":"2024-03-11T14:34:04.096616Z","iopub.status.idle":"2024-03-11T14:34:04.877327Z","shell.execute_reply.started":"2024-03-11T14:34:04.096576Z","shell.execute_reply":"2024-03-11T14:34:04.876252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion='breath'\npath = np.array(Nonspeech7k_df.Path[Nonspeech7k_df.Emotions==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:04.878841Z","iopub.execute_input":"2024-03-11T14:34:04.879271Z","iopub.status.idle":"2024-03-11T14:34:05.663316Z","shell.execute_reply.started":"2024-03-11T14:34:04.879231Z","shell.execute_reply":"2024-03-11T14:34:05.661675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion='screaming'\npath = np.array(Nonspeech7k_df.Path[Nonspeech7k_df.Emotions==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:05.665656Z","iopub.execute_input":"2024-03-11T14:34:05.666204Z","iopub.status.idle":"2024-03-11T14:34:06.308838Z","shell.execute_reply.started":"2024-03-11T14:34:05.66615Z","shell.execute_reply":"2024-03-11T14:34:06.307555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"def noise(data):\n    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef stretch(data, rate=0.8):\n    return librosa.effects.time_stretch(data, rate)\n\ndef shift(data):\n    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n    return np.roll(data, shift_range)\n\ndef pitch(data, sampling_rate, pitch_factor=0.7):\n    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n\n# taking any example and checking for techniques.\npath = np.array(Nonspeech7k_df.Path)[1]\ndata, sample_rate = librosa.load(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:06.310828Z","iopub.execute_input":"2024-03-11T14:34:06.311436Z","iopub.status.idle":"2024-03-11T14:34:06.458767Z","shell.execute_reply.started":"2024-03-11T14:34:06.311376Z","shell.execute_reply":"2024-03-11T14:34:06.45743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1. Simple Audio","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,4))\nlibrosa.display.waveplot(y=data, sr=sample_rate)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:06.460626Z","iopub.execute_input":"2024-03-11T14:34:06.461038Z","iopub.status.idle":"2024-03-11T14:34:06.660314Z","shell.execute_reply.started":"2024-03-11T14:34:06.460992Z","shell.execute_reply":"2024-03-11T14:34:06.659091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Noise Injection","metadata":{}},{"cell_type":"code","source":"x = noise(data)\nplt.figure(figsize=(14,4))\nlibrosa.display.waveplot(y=x, sr=sample_rate)\nAudio(x, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:06.662546Z","iopub.execute_input":"2024-03-11T14:34:06.663142Z","iopub.status.idle":"2024-03-11T14:34:06.886475Z","shell.execute_reply.started":"2024-03-11T14:34:06.663089Z","shell.execute_reply":"2024-03-11T14:34:06.885414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Stretching","metadata":{}},{"cell_type":"code","source":"x = stretch(data)\nplt.figure(figsize=(14,4))\nlibrosa.display.waveplot(y=x, sr=sample_rate)\nAudio(x, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:06.888073Z","iopub.execute_input":"2024-03-11T14:34:06.888635Z","iopub.status.idle":"2024-03-11T14:34:08.061337Z","shell.execute_reply.started":"2024-03-11T14:34:06.888577Z","shell.execute_reply":"2024-03-11T14:34:08.060273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4. Shifting","metadata":{}},{"cell_type":"code","source":"x = shift(data)\nplt.figure(figsize=(14,4))\nlibrosa.display.waveplot(y=x, sr=sample_rate)\nAudio(x, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:08.062928Z","iopub.execute_input":"2024-03-11T14:34:08.063379Z","iopub.status.idle":"2024-03-11T14:34:08.265671Z","shell.execute_reply.started":"2024-03-11T14:34:08.063341Z","shell.execute_reply":"2024-03-11T14:34:08.264302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. Pitch","metadata":{}},{"cell_type":"code","source":"x = pitch(data, sample_rate)\nplt.figure(figsize=(14,4))\nlibrosa.display.waveplot(y=x, sr=sample_rate)\nAudio(x, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:08.267368Z","iopub.execute_input":"2024-03-11T14:34:08.267728Z","iopub.status.idle":"2024-03-11T14:34:08.61952Z","shell.execute_reply.started":"2024-03-11T14:34:08.267694Z","shell.execute_reply":"2024-03-11T14:34:08.616392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(data):\n    # ZCR\n    result = np.array([])\n    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n    result=np.hstack((result, zcr)) # stacking horizontally\n    \n    #Spectral_Centroid\n    sc = np.mean(librosa.feature.spectral_centroid(y=data).T, axis=0)\n    result=np.hstack((result, sc)) # stacking horizontally\n    \n    #Spectral_Rolloff\n    spr = np.mean(librosa.feature.spectral_rolloff(y=data).T, axis=0)\n    result=np.hstack((result, spr)) # stacking horizontally\n\n    # Chroma_stft\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, chroma_stft)) # stacking horizontally\n\n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mfcc)) # stacking horizontally\n\n    # Root Mean Square Value\n    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n    result = np.hstack((result, rms)) # stacking horizontally\n\n    # MelSpectogram\n    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mel)) # stacking horizontally\n    \n    return result\n\ndef get_features(path):\n    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n    data, sample_rate = librosa.load(path,sr = None, duration=2.5, offset=0.6)\n    if data is None or len(data) == 0:\n        return np.array([])\n    # without augmentation\n    res1 = extract_features(data)\n    result = np.array(res1)\n    \n    # data with noise\n    noise_data = noise(data)\n    res2 = extract_features(noise_data)\n    result = np.vstack((result, res2)) # stacking vertically\n    \n    # data with stretching and pitching\n    new_data = stretch(data)\n    data_stretch_pitch = pitch(new_data, sample_rate)\n    res3 = extract_features(data_stretch_pitch)\n    result = np.vstack((result, res3)) # stacking vertically\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:08.621519Z","iopub.execute_input":"2024-03-11T14:34:08.621908Z","iopub.status.idle":"2024-03-11T14:34:08.678143Z","shell.execute_reply.started":"2024-03-11T14:34:08.62186Z","shell.execute_reply":"2024-03-11T14:34:08.672233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, Y = [], []\nfor path, emotion in zip(Nonspeech7k_df.Path, Nonspeech7k_df.Emotions):\n    feature = get_features(path)\n    if len(feature) == 0:\n        continue\n    for ele in feature:\n        X.append(ele)\n        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n        Y.append(emotion)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:34:08.688199Z","iopub.execute_input":"2024-03-11T14:34:08.69105Z","iopub.status.idle":"2024-03-11T14:45:12.979219Z","shell.execute_reply.started":"2024-03-11T14:34:08.69098Z","shell.execute_reply":"2024-03-11T14:45:12.977698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X), len(Y), Nonspeech7k_df.Path.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:12.981552Z","iopub.execute_input":"2024-03-11T14:45:12.981998Z","iopub.status.idle":"2024-03-11T14:45:12.991483Z","shell.execute_reply.started":"2024-03-11T14:45:12.981953Z","shell.execute_reply":"2024-03-11T14:45:12.990235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Features = pd.DataFrame(X)\nFeatures['labels'] = Y\nFeatures.to_csv('features.csv', index=False)\nFeatures","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:12.993359Z","iopub.execute_input":"2024-03-11T14:45:12.99378Z","iopub.status.idle":"2024-03-11T14:45:16.267875Z","shell.execute_reply.started":"2024-03-11T14:45:12.993743Z","shell.execute_reply":"2024-03-11T14:45:16.267023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"X = Features.iloc[: ,:-1].values\nY = Features['labels'].values","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:16.269316Z","iopub.execute_input":"2024-03-11T14:45:16.269848Z","iopub.status.idle":"2024-03-11T14:45:16.287518Z","shell.execute_reply.started":"2024-03-11T14:45:16.269792Z","shell.execute_reply":"2024-03-11T14:45:16.286289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As this is a multiclass classification problem onehotencoding our Y.\nencoder = OneHotEncoder()\nY = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:16.293585Z","iopub.execute_input":"2024-03-11T14:45:16.294385Z","iopub.status.idle":"2024-03-11T14:45:16.305423Z","shell.execute_reply.started":"2024-03-11T14:45:16.294338Z","shell.execute_reply":"2024-03-11T14:45:16.303819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0, shuffle=True)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:16.30769Z","iopub.execute_input":"2024-03-11T14:45:16.308188Z","iopub.status.idle":"2024-03-11T14:45:16.331333Z","shell.execute_reply.started":"2024-03-11T14:45:16.308145Z","shell.execute_reply":"2024-03-11T14:45:16.330308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scaling our data with sklearn's Standard scaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:16.33304Z","iopub.execute_input":"2024-03-11T14:45:16.333414Z","iopub.status.idle":"2024-03-11T14:45:16.361087Z","shell.execute_reply.started":"2024-03-11T14:45:16.333378Z","shell.execute_reply":"2024-03-11T14:45:16.360103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:16.362697Z","iopub.execute_input":"2024-03-11T14:45:16.363091Z","iopub.status.idle":"2024-03-11T14:45:16.371228Z","shell.execute_reply.started":"2024-03-11T14:45:16.363055Z","shell.execute_reply":"2024-03-11T14:45:16.370241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CNN Model**","metadata":{}},{"cell_type":"code","source":"# making our data compatible to model.\nx_train = np.expand_dims(x_train, axis=2)\nx_test = np.expand_dims(x_test, axis=2)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:38:39.889838Z","iopub.status.idle":"2024-03-10T05:38:39.890355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=32, activation='relu'))\n# model.add(Dropout(0.3))\n\nmodel.add(Dense(units=7, activation='softmax'))\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:38:39.891494Z","iopub.status.idle":"2024-03-10T05:38:39.891987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhist_cnn=model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:38:39.89306Z","iopub.status.idle":"2024-03-10T05:38:39.893594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred_cnn = encoder.inverse_transform(y_pred)\ny_test_cnn = encoder.inverse_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:38:39.89466Z","iopub.status.idle":"2024-03-10T05:38:39.895155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cnn = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf_cnn['Predicted Labels'] = y_pred_cnn.flatten()\ndf_cnn['Actual Labels'] = y_test_cnn.flatten()\n\ndf_cnn.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:38:39.896166Z","iopub.status.idle":"2024-03-10T05:38:39.896702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nprint(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\nepochs = [i for i in range(100)]\nfig , ax = plt.subplots(1,3)\ntrain_acc = hist_cnn.history['accuracy']\n# train_acc = train_acc[10:40]\ntrain_loss = hist_cnn.history['loss']\n# train_loss = train_loss[10:40]\ntest_acc = hist_cnn.history['val_accuracy']\n# test_acc = test_acc[10:40]\ntest_loss = hist_cnn.history['val_loss']\n# test_loss = test_loss[10:40]\n\nlabels=['breath', 'cough', 'crying', 'laugh', 'scream', 'sneeze','yawn']\nfig.set_size_inches(20,4)\n# plt.rcParams['axes.grid'] = False\nplt.rcParams['font.weight'] = \"bold\"\nax[1].plot(epochs , train_loss , label = 'Training Loss')\nax[1].plot(epochs , test_loss , label = 'Testing Loss')\nax[1].set_title('Model Loss',fontweight=\"bold\",fontsize = 15)\nax[1].legend()\nax[1].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\nax[0].plot(epochs , train_acc , label = 'Training Accuracy')\nax[0].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[0].set_title('Model Accuracy',fontweight=\"bold\",fontsize = 15)\nax[0].legend()\nax[0].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\ncf_matrix = confusion_matrix(y_test_cnn, y_pred_cnn)\ndisp = ConfusionMatrixDisplay(cf_matrix, display_labels=epochs)\ndisp.plot(ax=ax[2],xticks_rotation='vertical',cmap=\"afmhot\")\ndisp.ax_.set_title(\"Confusion Matrix\", fontweight=\"bold\",fontsize = 15)\ndisp.ax_.set_xticklabels(labels, fontsize = 11)\ndisp.ax_.set_yticklabels(labels, fontsize = 11)\ndisp.im_.colorbar.remove()\ndisp.ax_.set_xlabel('')\ndisp.ax_.set_ylabel('True label',fontweight=\"bold\", fontsize = 15)\ndisp.ax_.set_xlabel('Predicted label', fontweight=\"bold\", fontsize = 15)\n\nfig.text(0.45, -0.14, 'CNN Model', fontweight=\"bold\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:38:39.897754Z","iopub.status.idle":"2024-03-10T05:38:39.898228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test_cnn, y_pred_cnn))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **LSTM Model**","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, TimeDistributed, Conv1D, MaxPooling1D, Flatten\nimport numpy as np\n\n# Sample data shapes\nx_train_shape = (4077, 164)\ny_train_lstm = (4077, 7)\nx_test_shape = (1020, 164)\ny_test_lstm = (1020, 7)\n\n# Reshape the data to 3D\nx_train_lstm = np.reshape(x_train, (x_train_shape[0], x_train_shape[1], 1))\n\nx_train_lstm.shape, x_train.shape, y_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the model\nmodelLSTM = Sequential([\n    LSTM(256, return_sequences=False, input_shape=(164, 1)),\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax'),\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-09T04:02:20.058876Z","iopub.execute_input":"2024-03-09T04:02:20.059593Z","iopub.status.idle":"2024-03-09T04:02:20.384281Z","shell.execute_reply.started":"2024-03-09T04:02:20.059527Z","shell.execute_reply":"2024-03-09T04:02:20.383245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelLSTM.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\nmodelLSTM.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T04:02:23.818781Z","iopub.execute_input":"2024-03-09T04:02:23.819505Z","iopub.status.idle":"2024-03-09T04:02:23.879603Z","shell.execute_reply.started":"2024-03-09T04:02:23.819442Z","shell.execute_reply":"2024-03-09T04:02:23.878339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_lstm = modelLSTM.fit(x_train_lstm, y_train, validation_data=(x_test_lstm, y_test), batch_size=32, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T04:02:25.958449Z","iopub.execute_input":"2024-03-09T04:02:25.958901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_lstm = modelLSTM.predict(x_test_lstm)\ny_pred = encoder.inverse_transform(y_pred_lstm)\ny_test_lstm = encoder.inverse_transform(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_lstm = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf_lstm['Predicted Labels'] = y_pred.flatten()\ndf_lstm['Actual Labels'] = y_test_lstm.flatten()\n\ndf_lstm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nprint(\"Accuracy of our model on test data : \" ,modelLSTM.evaluate(x_test_lstm,y_test)[1]*100 , \"%\")\nepochs = [i for i in range(30)]\nfig , ax = plt.subplots(1,3)\ntrain_acc = hist_lstm.history['accuracy']\n# train_acc = train_acc[10:40]\ntrain_loss = hist_lstm.history['loss']\n# train_loss = train_loss[10:40]\ntest_acc = hist_lstm.history['val_accuracy']\n# test_acc = test_acc[10:40]\ntest_loss = hist_lstm.history['val_loss']\n# test_loss = test_loss[10:40]\n\nlabels=['breath', 'cough', 'crying', 'laugh', 'scream', 'sneeze','yawn']\nfig.set_size_inches(20,4)\n# plt.rcParams['axes.grid'] = False\nplt.rcParams['font.weight'] = \"bold\"\nax[1].plot(epochs , train_loss , label = 'Training Loss')\nax[1].plot(epochs , test_loss , label = 'Testing Loss')\nax[1].set_title('Model Loss',fontweight=\"bold\",fontsize = 15)\nax[1].legend()\nax[1].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\nax[0].plot(epochs , train_acc , label = 'Training Accuracy')\nax[0].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[0].set_title('Model Accuracy',fontweight=\"bold\",fontsize = 15)\nax[0].legend()\nax[0].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\ncf_matrix = confusion_matrix(y_test_lstm, y_pred)\ndisp = ConfusionMatrixDisplay(cf_matrix, display_labels=epochs)\ndisp.plot(ax=ax[2],xticks_rotation='vertical',cmap=\"Greens\")\ndisp.ax_.set_title(\"Confusion Matrix\", fontweight=\"bold\",fontsize = 15)\ndisp.ax_.set_xticklabels(labels, fontsize = 11)\ndisp.ax_.set_yticklabels(labels, fontsize = 11)\ndisp.im_.colorbar.remove()\ndisp.ax_.set_xlabel('')\ndisp.ax_.set_ylabel('True label',fontweight=\"bold\", fontsize = 15)\ndisp.ax_.set_xlabel('Predicted label', fontweight=\"bold\", fontsize = 15)\n\nfig.text(0.45, -0.14, 'LSTM Model', fontweight=\"bold\", fontsize = 20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test_lstm, y_pred_lstm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BiLSTM Model**","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, TimeDistributed, Conv1D, MaxPooling1D, Flatten\nimport numpy as np\n\n# Sample data shapes\nx_train_shape = (4077, 164)\ny_train_bilstm = (4077, 7)\nx_test_shape = (1020, 164)\ny_test_bilstm = (1020, 7)\n\n# Reshape the data to 3D\nx_train_bilstm = np.reshape(x_train, (x_train_shape[0], x_train_shape[1], 1))\nx_test_bilstm = np.reshape(x_test, (x_test_shape[0], x_test_shape[1], 1))\n\nx_train_bilstm.shape, x_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-09T17:14:18.667284Z","iopub.execute_input":"2024-03-09T17:14:18.667607Z","iopub.status.idle":"2024-03-09T17:14:18.682343Z","shell.execute_reply.started":"2024-03-09T17:14:18.667576Z","shell.execute_reply":"2024-03-09T17:14:18.68109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Bidirectional\nmodelBiLSTM = Sequential([\n    Bidirectional(LSTM(128, return_sequences=False, input_shape=(164, 1))),\n    Dropout(0.3),\n    Dense(64, activation='relu'),\n    Dropout(0.3),\n    Dense(32, activation='relu'),\n    Dropout(0.3),\n    Dense(7, activation='softmax'),\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-09T17:14:18.683902Z","iopub.execute_input":"2024-03-09T17:14:18.684356Z","iopub.status.idle":"2024-03-09T17:14:18.706176Z","shell.execute_reply.started":"2024-03-09T17:14:18.684317Z","shell.execute_reply":"2024-03-09T17:14:18.704649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelBiLSTM.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodelBiLSTM.build((None, 164, 1))\nmodelBiLSTM.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T17:14:18.709189Z","iopub.execute_input":"2024-03-09T17:14:18.709882Z","iopub.status.idle":"2024-03-09T17:14:19.177352Z","shell.execute_reply.started":"2024-03-09T17:14:18.709829Z","shell.execute_reply":"2024-03-09T17:14:19.176319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhist_bilstm = modelBiLSTM.fit(x_train_bilstm, y_train, validation_data=(x_test_bilstm, y_test), batch_size=32, epochs=120, callbacks=[rlrp])","metadata":{"execution":{"iopub.status.busy":"2024-03-09T17:14:19.178794Z","iopub.execute_input":"2024-03-09T17:14:19.179166Z","iopub.status.idle":"2024-03-09T18:07:00.714003Z","shell.execute_reply.started":"2024-03-09T17:14:19.179132Z","shell.execute_reply":"2024-03-09T18:07:00.712812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_bilstm = modelBiLSTM.predict(x_test_bilstm)\ny_pred = encoder.inverse_transform(y_pred_bilstm)\ny_test_bilstm = encoder.inverse_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T18:07:00.71565Z","iopub.execute_input":"2024-03-09T18:07:00.716024Z","iopub.status.idle":"2024-03-09T18:07:02.474709Z","shell.execute_reply.started":"2024-03-09T18:07:00.715988Z","shell.execute_reply":"2024-03-09T18:07:02.473448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bilstm = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf_bilstm['Predicted Labels'] = y_pred.flatten()\ndf_bilstm['Actual Labels'] = y_test_bilstm.flatten()\n\ndf_bilstm","metadata":{"execution":{"iopub.status.busy":"2024-03-09T18:07:02.477316Z","iopub.execute_input":"2024-03-09T18:07:02.477861Z","iopub.status.idle":"2024-03-09T18:07:02.501979Z","shell.execute_reply.started":"2024-03-09T18:07:02.477805Z","shell.execute_reply":"2024-03-09T18:07:02.500711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nprint(\"Accuracy of our model on test data : \" ,modelBiLSTM.evaluate(x_test_bilstm,y_test)[1]*100 , \"%\")\nepochs = [i for i in range(100)]\nfig , ax = plt.subplots(1,3)\ntrain_acc = hist_bilstm.history['accuracy']\ntrain_acc = train_acc[20:120]\ntrain_loss = hist_bilstm.history['loss']\ntrain_loss = train_loss[20:120]\ntest_acc = hist_bilstm.history['val_accuracy']\ntest_acc = test_acc[20:120]\ntest_loss = hist_bilstm.history['val_loss']\ntest_loss = test_loss[20:120]\n\nlabels=['breath', 'cough', 'crying', 'laugh', 'scream', 'sneeze','yawn']\nfig.set_size_inches(20,4)\n# plt.rcParams['axes.grid'] = False\nplt.rcParams['font.weight'] = \"bold\"\nax[1].plot(epochs , train_loss , label = 'Training Loss')\nax[1].plot(epochs , test_loss , label = 'Testing Loss')\nax[1].set_title('Model Loss',fontweight=\"bold\",fontsize = 15)\nax[1].legend()\nax[1].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\nax[0].plot(epochs , train_acc , label = 'Training Accuracy')\nax[0].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[0].set_title('Model Accuracy',fontweight=\"bold\",fontsize = 15)\nax[0].legend()\nax[0].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\ncf_matrix = confusion_matrix(y_test_bilstm, y_pred)\ndisp = ConfusionMatrixDisplay(cf_matrix, display_labels=epochs)\ndisp.plot(ax=ax[2],xticks_rotation='vertical',cmap=\"Greens\")\ndisp.ax_.set_title(\"Confusion Matrix\", fontweight=\"bold\",fontsize = 15)\ndisp.ax_.set_xticklabels(labels, fontsize = 11)\ndisp.ax_.set_yticklabels(labels, fontsize = 11)\ndisp.im_.colorbar.remove()\ndisp.ax_.set_xlabel('')\ndisp.ax_.set_ylabel('True label',fontweight=\"bold\", fontsize = 15)\ndisp.ax_.set_xlabel('Predicted label', fontweight=\"bold\", fontsize = 15)\n\nfig.text(0.45, -0.14, 'BiLSTM Model', fontweight=\"bold\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:04:27.349362Z","iopub.execute_input":"2024-03-11T07:04:27.34985Z","iopub.status.idle":"2024-03-11T07:04:27.405388Z","shell.execute_reply.started":"2024-03-11T07:04:27.349809Z","shell.execute_reply":"2024-03-11T07:04:27.403313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1D Resnet**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Sample data shapes\nx_train_shape = (4077, 164)\ny_train_1d_resnet = (4077, 7)\nx_test_shape = (1020, 164)\ny_test_1d_resnet = (1020, 7)\n\n# Reshape the data to 3D\nx_train_1d_resnet = np.reshape(x_train, (x_train_shape[0], x_train_shape[1], 1))\nx_test_1d_resnet = np.reshape(x_test, (x_test_shape[0], x_test_shape[1], 1))\n\nx_train_1d_resnet.shape, x_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-10T06:18:34.553998Z","iopub.execute_input":"2024-03-10T06:18:34.554453Z","iopub.status.idle":"2024-03-10T06:18:34.566996Z","shell.execute_reply.started":"2024-03-10T06:18:34.554403Z","shell.execute_reply":"2024-03-10T06:18:34.565619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add\n\ndef residual_block(x, filters, kernel_size, dilation_rate):\n    # Shortcut connection\n    shortcut = x\n    \n    # Main path\n    x = Conv1D(filters, kernel_size, dilation_rate=dilation_rate, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv1D(filters, kernel_size, dilation_rate=dilation_rate, padding='same')(x)\n    x = BatchNormalization()(x)\n    \n    # Add shortcut value to main path\n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2024-03-10T09:53:47.175899Z","iopub.execute_input":"2024-03-10T09:53:47.176343Z","iopub.status.idle":"2024-03-10T09:53:47.18696Z","shell.execute_reply.started":"2024-03-10T09:53:47.176289Z","shell.execute_reply":"2024-03-10T09:53:47.185698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\ndef build_1d_resnet(input_shape, num_classes):\n    inputs = Input(shape=input_shape)\n    \n    x = Conv1D(64, 7, padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # 4 Residual blocks\n#     x = residual_block(x, filters=64, kernel_size=3, dilation_rate=1)\n#     x = residual_block(x, filters=64, kernel_size=3, dilation_rate=2)\n#     x = residual_block(x, filters=64, kernel_size=3, dilation_rate=4)\n#     x = residual_block(x, filters=64, kernel_size=3, dilation_rate=8)\n    \n    x = Flatten()(x)\n    \n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(32, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    \n    outputs = Dense(num_classes, activation='softmax')(x)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\ninput_shape = (164, 1) \nnum_classes = 7\n\nmodel_1d_resnet = build_1d_resnet(input_shape, num_classes)\nmodel_1d_resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_1d_resnet.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T09:53:47.369713Z","iopub.execute_input":"2024-03-10T09:53:47.370097Z","iopub.status.idle":"2024-03-10T09:53:47.574547Z","shell.execute_reply.started":"2024-03-10T09:53:47.370063Z","shell.execute_reply":"2024-03-10T09:53:47.573616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhist_1d_resnet = model_1d_resnet.fit(x_train_1d_resnet, y_train, validation_data=(x_test_1d_resnet, y_test), batch_size=32, epochs=120, callbacks=[rlrp])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T09:53:47.670694Z","iopub.execute_input":"2024-03-10T09:53:47.671078Z","iopub.status.idle":"2024-03-10T09:57:38.98766Z","shell.execute_reply.started":"2024-03-10T09:53:47.671045Z","shell.execute_reply":"2024-03-10T09:57:38.986712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_1d_resnet = model_1d_resnet.predict(x_test_1d_resnet)\ny_pred = encoder.inverse_transform(y_pred_1d_resnet)\ny_test_1d_resnet = encoder.inverse_transform(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_1d_resnet = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf_1d_resnet['Predicted Labels'] = y_pred.flatten()\ndf_1d_resnet['Actual Labels'] = y_test_1d_resnet.flatten()\n\ndf_1d_resnet","metadata":{"execution":{"iopub.status.busy":"2024-03-10T09:46:49.174357Z","iopub.execute_input":"2024-03-10T09:46:49.17481Z","iopub.status.idle":"2024-03-10T09:46:49.199863Z","shell.execute_reply.started":"2024-03-10T09:46:49.174761Z","shell.execute_reply":"2024-03-10T09:46:49.198649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nprint(\"Accuracy of our model on test data : \" ,model_1d_resnet.evaluate(x_test_1d_resnet,y_test)[1]*100 , \"%\")\nepochs = [i for i in range(100)]\nfig , ax = plt.subplots(1,3)\ntrain_acc = hist_1d_resnet.history['accuracy']\ntrain_acc = train_acc[20:120]\ntrain_loss = hist_1d_resnet.history['loss']\ntrain_loss = train_loss[20:120]\ntest_acc = hist_1d_resnet.history['val_accuracy']\ntest_acc = test_acc[20:120]\ntest_loss = hist_1d_resnet.history['val_loss']\ntest_loss = test_loss[20:120]\n\nlabels=['breath', 'cough', 'crying', 'laugh', 'scream', 'sneeze','yawn']\nfig.set_size_inches(20,4)\n# plt.rcParams['axes.grid'] = False\nplt.rcParams['font.weight'] = \"bold\"\nax[1].plot(epochs , train_loss , label = 'Training Loss')\nax[1].plot(epochs , test_loss , label = 'Testing Loss')\nax[1].set_title('Model Loss',fontweight=\"bold\",fontsize = 15)\nax[1].legend()\nax[1].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\nax[0].plot(epochs , train_acc , label = 'Training Accuracy')\nax[0].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[0].set_title('Model Accuracy',fontweight=\"bold\",fontsize = 15)\nax[0].legend()\nax[0].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\ncf_matrix = confusion_matrix(y_test_1d_resnet, y_pred)\ndisp = ConfusionMatrixDisplay(cf_matrix, display_labels=epochs)\ndisp.plot(ax=ax[2],xticks_rotation='vertical',cmap=\"Greens\")\ndisp.ax_.set_title(\"Confusion Matrix\", fontweight=\"bold\",fontsize = 15)\ndisp.ax_.set_xticklabels(labels, fontsize = 11)\ndisp.ax_.set_yticklabels(labels, fontsize = 11)\ndisp.im_.colorbar.remove()\ndisp.ax_.set_xlabel('')\ndisp.ax_.set_ylabel('True label',fontweight=\"bold\", fontsize = 15)\ndisp.ax_.set_xlabel('Predicted label', fontweight=\"bold\", fontsize = 15)\n\nfig.text(0.45, -0.14, '1D Resnet Model', fontweight=\"bold\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T09:46:49.201571Z","iopub.execute_input":"2024-03-10T09:46:49.201908Z","iopub.status.idle":"2024-03-10T09:46:50.456909Z","shell.execute_reply.started":"2024-03-10T09:46:49.201875Z","shell.execute_reply":"2024-03-10T09:46:50.455872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TDNN**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Sample data shapes\nx_train_shape = (4077, 164)\ny_train_tdnn = (4077, 7)\nx_test_shape = (1020, 164)\ny_test_tdnn = (1020, 7)\n\n# Reshape the data to 3D\nx_train_tdnn = np.reshape(x_train, (x_train_shape[0], x_train_shape[1], 1))\nx_test_tdnn = np.reshape(x_test, (x_test_shape[0], x_test_shape[1], 1))\n\nx_train_tdnn.shape, x_test_tdnn.shape, x_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-10T16:33:36.706705Z","iopub.execute_input":"2024-03-10T16:33:36.707471Z","iopub.status.idle":"2024-03-10T16:33:36.720958Z","shell.execute_reply.started":"2024-03-10T16:33:36.70743Z","shell.execute_reply":"2024-03-10T16:33:36.719363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n\ndef build_tdnn_model(input_shape, num_classes):\n    model = Sequential([\n        Conv1D(64, 3, activation='relu', input_shape=input_shape, padding='same'),\n        MaxPooling1D(2),\n        Conv1D(128, 3, activation='relu', padding='same'),\n        MaxPooling1D(2),\n        Conv1D(256, 3, activation='relu', padding='same'),\n        MaxPooling1D(2),\n        Conv1D(512, 3, activation='relu', padding='same'),\n        MaxPooling1D(2),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\ninput_shape = (164, 1)\nnum_classes = 7\n\nmodel_tdnn = build_tdnn_model(input_shape, num_classes)\nmodel_tdnn.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_tdnn.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:06:48.735175Z","iopub.execute_input":"2024-03-10T17:06:48.7356Z","iopub.status.idle":"2024-03-10T17:06:48.917943Z","shell.execute_reply.started":"2024-03-10T17:06:48.735567Z","shell.execute_reply":"2024-03-10T17:06:48.916113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhist_tdnn = model_tdnn.fit(x_train_tdnn, y_train, validation_data=(x_test_tdnn, y_test), batch_size=32, epochs=120, callbacks=[rlrp])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:06:49.686071Z","iopub.execute_input":"2024-03-10T17:06:49.686495Z","iopub.status.idle":"2024-03-10T17:23:52.542382Z","shell.execute_reply.started":"2024-03-10T17:06:49.686456Z","shell.execute_reply":"2024-03-10T17:23:52.540662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_tdnn = model_tdnn.predict(x_test_tdnn)\ny_pred = encoder.inverse_transform(y_pred_tdnn)\ny_test_tdnn = encoder.inverse_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:23:52.545459Z","iopub.execute_input":"2024-03-10T17:23:52.546225Z","iopub.status.idle":"2024-03-10T17:23:53.110541Z","shell.execute_reply.started":"2024-03-10T17:23:52.546163Z","shell.execute_reply":"2024-03-10T17:23:53.109429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_1d_tdnn = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf_1d_tdnn['Predicted Labels'] = y_pred.flatten()\ndf_1d_tdnn['Actual Labels'] = y_test_tdnn.flatten()\n\ndf_1d_tdnn","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:23:53.114687Z","iopub.execute_input":"2024-03-10T17:23:53.115071Z","iopub.status.idle":"2024-03-10T17:23:53.140313Z","shell.execute_reply.started":"2024-03-10T17:23:53.115031Z","shell.execute_reply":"2024-03-10T17:23:53.139493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nprint(\"Accuracy of our model on test data : \" ,model_tdnn.evaluate(x_test_tdnn,y_test)[1]*100 , \"%\")\nepochs = [i for i in range(110)]\nfig , ax = plt.subplots(1,3)\ntrain_acc = hist_tdnn.history['accuracy']\ntrain_acc = train_acc[10:120]\ntrain_loss = hist_tdnn.history['loss']\ntrain_loss = train_loss[10:120]\ntest_acc = hist_tdnn.history['val_accuracy']\ntest_acc = test_acc[10:120]\ntest_loss = hist_tdnn.history['val_loss']\ntest_loss = test_loss[10:120]\n\nlabels=['breath', 'cough', 'crying', 'laugh', 'scream', 'sneeze','yawn']\nfig.set_size_inches(20,4)\n# plt.rcParams['axes.grid'] = False\nplt.rcParams['font.weight'] = \"bold\"\nax[1].plot(epochs , train_loss , label = 'Training Loss')\nax[1].plot(epochs , test_loss , label = 'Testing Loss')\nax[1].set_title('Model Loss',fontweight=\"bold\",fontsize = 15)\nax[1].legend()\nax[1].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\nax[0].plot(epochs , train_acc , label = 'Training Accuracy')\nax[0].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[0].set_title('Model Accuracy',fontweight=\"bold\",fontsize = 15)\nax[0].legend()\nax[0].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\ncf_matrix = confusion_matrix(y_test_tdnn, y_pred)\ndisp = ConfusionMatrixDisplay(cf_matrix, display_labels=epochs)\ndisp.plot(ax=ax[2],xticks_rotation='vertical',cmap=\"Greens\")\ndisp.ax_.set_title(\"Confusion Matrix\", fontweight=\"bold\",fontsize = 15)\ndisp.ax_.set_xticklabels(labels, fontsize = 11)\ndisp.ax_.set_yticklabels(labels, fontsize = 11)\ndisp.im_.colorbar.remove()\ndisp.ax_.set_xlabel('')\ndisp.ax_.set_ylabel('True label',fontweight=\"bold\", fontsize = 15)\ndisp.ax_.set_xlabel('Predicted label', fontweight=\"bold\", fontsize = 15)\n\nfig.text(0.45, -0.14, 'TDNN Model', fontweight=\"bold\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T18:17:59.339895Z","iopub.execute_input":"2024-03-10T18:17:59.340301Z","iopub.status.idle":"2024-03-10T18:18:00.563497Z","shell.execute_reply.started":"2024-03-10T18:17:59.340267Z","shell.execute_reply":"2024-03-10T18:18:00.561357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CNN-BiLSTM**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Sample data shapes\nx_train_shape = (4077, 164)\ny_train_CNN_BiLSTM = (4077, 7)\nx_test_shape = (1020, 164)\ny_test_CNN_BiLSTM = (1020, 7)\n\n# Reshape the data to 3D\nx_train_CNN_BiLSTM = np.reshape(x_train, (x_train_shape[0], x_train_shape[1], 1))\nx_test_CNN_BiLSTM = np.reshape(x_test, (x_test_shape[0], x_test_shape[1], 1))\n\nx_train_CNN_BiLSTM.shape, x_test_CNN_BiLSTM.shape, x_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:58:15.465865Z","iopub.execute_input":"2024-03-11T14:58:15.466406Z","iopub.status.idle":"2024-03-11T14:58:15.483675Z","shell.execute_reply.started":"2024-03-11T14:58:15.466364Z","shell.execute_reply":"2024-03-11T14:58:15.48158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Bidirectional, LSTM\n\nmodel_CNN_BiLSTM = Sequential([\n    Conv1D(128, 3, activation='relu'),\n    MaxPooling1D(2),\n    Conv1D(64, 3, activation='relu', input_shape=(164, 1)),\n    MaxPooling1D(2),\n    Dropout(0.3),\n    Bidirectional(LSTM(64, return_sequences=True)),\n    Dropout(0.3),\n    Bidirectional(LSTM(32)),\n    Dense(64, activation='relu'),\n    Dropout(0.3),\n    Dense(7, activation='softmax')  # Adjust the number of units for your classification task\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:58:15.948508Z","iopub.execute_input":"2024-03-11T14:58:15.948997Z","iopub.status.idle":"2024-03-11T14:58:16.009672Z","shell.execute_reply.started":"2024-03-11T14:58:15.948957Z","shell.execute_reply":"2024-03-11T14:58:16.008036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_CNN_BiLSTM.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_CNN_BiLSTM.build((None, 164, 1))\nmodel_CNN_BiLSTM.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:58:16.01282Z","iopub.execute_input":"2024-03-11T14:58:16.013664Z","iopub.status.idle":"2024-03-11T14:58:17.526521Z","shell.execute_reply.started":"2024-03-11T14:58:16.013601Z","shell.execute_reply":"2024-03-11T14:58:17.525386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhist_CNN_BiLSTM = model_CNN_BiLSTM.fit(x_train_CNN_BiLSTM, y_train, validation_data=(x_test_CNN_BiLSTM, y_test), batch_size=32, epochs=120, callbacks=[rlrp])","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:58:17.528004Z","iopub.execute_input":"2024-03-11T14:58:17.528539Z","iopub.status.idle":"2024-03-11T15:22:41.872166Z","shell.execute_reply.started":"2024-03-11T14:58:17.5285Z","shell.execute_reply":"2024-03-11T15:22:41.870504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_CNN_BiLSTM = model_CNN_BiLSTM.predict(x_test_CNN_BiLSTM)\ny_pred = encoder.inverse_transform(y_pred_CNN_BiLSTM)\ny_test_CNN_BiLSTM = encoder.inverse_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:47:46.33188Z","iopub.execute_input":"2024-03-11T15:47:46.332416Z","iopub.status.idle":"2024-03-11T15:47:47.075767Z","shell.execute_reply.started":"2024-03-11T15:47:46.332363Z","shell.execute_reply":"2024-03-11T15:47:47.074619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_CNN_BiLSTM = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf_CNN_BiLSTM['Predicted Labels'] = y_pred.flatten()\ndf_CNN_BiLSTM['Actual Labels'] = y_test_CNN_BiLSTM.flatten()\n\ndf_CNN_BiLSTM","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:47:47.078772Z","iopub.execute_input":"2024-03-11T15:47:47.07922Z","iopub.status.idle":"2024-03-11T15:47:47.105806Z","shell.execute_reply.started":"2024-03-11T15:47:47.079183Z","shell.execute_reply":"2024-03-11T15:47:47.104323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nprint(\"Accuracy of our model on test data : \" ,model_CNN_BiLSTM.evaluate(x_test_CNN_BiLSTM,y_test)[1]*100 , \"%\")\nepochs = [i for i in range(110)]\nfig , ax = plt.subplots(1,3)\ntrain_acc = hist_CNN_BiLSTM.history['accuracy']\ntrain_acc = train_acc[10:120]\ntrain_loss = hist_CNN_BiLSTM.history['loss']\ntrain_loss = train_loss[10:120]\ntest_acc = hist_CNN_BiLSTM.history['val_accuracy']\ntest_acc = test_acc[10:120]\ntest_loss = hist_CNN_BiLSTM.history['val_loss']\ntest_loss = test_loss[10:120]\n\nlabels=['breath', 'cough', 'crying', 'laugh', 'scream', 'sneeze','yawn']\nfig.set_size_inches(20,4)\n# plt.rcParams['axes.grid'] = False\nplt.rcParams['font.weight'] = \"bold\"\nax[1].plot(epochs , train_loss , label = 'Training Loss')\nax[1].plot(epochs , test_loss , label = 'Testing Loss')\nax[1].set_title('Model Loss',fontweight=\"bold\",fontsize = 15)\nax[1].legend()\nax[1].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\nax[0].plot(epochs , train_acc , label = 'Training Accuracy')\nax[0].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[0].set_title('Model Accuracy',fontweight=\"bold\",fontsize = 15)\nax[0].legend()\nax[0].set_xlabel(\"Number of Epochs\", fontweight=\"bold\", fontsize = 15)\n\ncf_matrix = confusion_matrix(y_test_CNN_BiLSTM, y_pred)\ndisp = ConfusionMatrixDisplay(cf_matrix, display_labels=epochs)\ndisp.plot(ax=ax[2],xticks_rotation='vertical',cmap=\"Greens\")\ndisp.ax_.set_title(\"Confusion Matrix\", fontweight=\"bold\",fontsize = 15)\ndisp.ax_.set_xticklabels(labels, fontsize = 11)\ndisp.ax_.set_yticklabels(labels, fontsize = 11)\ndisp.im_.colorbar.remove()\ndisp.ax_.set_xlabel('')\ndisp.ax_.set_ylabel('True label',fontweight=\"bold\", fontsize = 15)\ndisp.ax_.set_xlabel('Predicted label', fontweight=\"bold\", fontsize = 15)\n\nfig.text(0.45, -0.14, 'CNN-BiLSTM Model', fontweight=\"bold\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:48:09.50946Z","iopub.execute_input":"2024-03-11T15:48:09.509903Z","iopub.status.idle":"2024-03-11T15:48:11.066131Z","shell.execute_reply.started":"2024-03-11T15:48:09.50985Z","shell.execute_reply":"2024-03-11T15:48:11.064791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MLP Model**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Sample data shapes\nx_train_shape = (4077, 164)\ny_train_MLP = (4077, 7)\nx_test_shape = (1020, 164)\ny_test_MLP = (1020, 7)\n\n# Reshape the data to 3D\nx_train_MLP = np.reshape(x_train, (x_train_shape[0], x_train_shape[1], 1))\nx_test_MLP = np.reshape(x_test, (x_test_shape[0], x_test_shape[1], 1))\n\nx_train_MLP.shape, x_test_MLP.shape, x_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:45:44.302056Z","iopub.execute_input":"2024-03-11T14:45:44.302579Z","iopub.status.idle":"2024-03-11T14:45:44.316622Z","shell.execute_reply.started":"2024-03-11T14:45:44.302535Z","shell.execute_reply":"2024-03-11T14:45:44.314854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmodel_MLP = MLPClassifier(batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300), learning_rate='adaptive', max_iter=500, solver='adam')\nhist_MLP = model_MLP.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:49:26.814176Z","iopub.execute_input":"2024-03-11T14:49:26.814973Z","iopub.status.idle":"2024-03-11T14:50:05.234836Z","shell.execute_reply.started":"2024-03-11T14:49:26.814926Z","shell.execute_reply":"2024-03-11T14:50:05.23349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_MLP = model_MLP.predict(x_test)\ny_pred = encoder.inverse_transform(y_pred_MLP)\ny_test_MLP = encoder.inverse_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:50:49.301776Z","iopub.execute_input":"2024-03-11T14:50:49.302281Z","iopub.status.idle":"2024-03-11T14:50:49.316626Z","shell.execute_reply.started":"2024-03-11T14:50:49.302243Z","shell.execute_reply":"2024-03-11T14:50:49.315534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_MLP = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf_MLP['Predicted Labels'] = y_pred.flatten()\ndf_MLP['Actual Labels'] = y_test_MLP.flatten()\n\ndf_MLP","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:50:51.293612Z","iopub.execute_input":"2024-03-11T14:50:51.294086Z","iopub.status.idle":"2024-03-11T14:50:51.320532Z","shell.execute_reply.started":"2024-03-11T14:50:51.294041Z","shell.execute_reply":"2024-03-11T14:50:51.318733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_true=y_test_MLP, y_pred=y_pred)\nprint('Achieved Accuracy: {:.2f}%'.format(accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:56:57.203514Z","iopub.execute_input":"2024-03-11T14:56:57.204633Z","iopub.status.idle":"2024-03-11T14:56:57.221369Z","shell.execute_reply.started":"2024-03-11T14:56:57.204555Z","shell.execute_reply":"2024-03-11T14:56:57.217877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\nconf_matrix = confusion_matrix(y_test_MLP, y_pred)\nfig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(6,6), cmap=plt.cm.Blues)\nlabels=['breath', 'cough', 'crying', 'laugh', 'scream', 'sneeze','yawn']\nax.set_xlabel('Predicted labels', fontsize=14, weight = 'bold')\nax.set_ylabel('True labels', fontsize=14, weight = 'bold')\nax.set_title('Confusion Matrix Using MLP', fontsize=16, weight = 'bold')\nax.set_xticklabels(labels, fontsize = 11)\nax.set_yticklabels(labels, fontsize = 11)\nplt.setp(ax.get_xticklabels(), rotation=35, horizontalalignment='right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:55:43.080857Z","iopub.execute_input":"2024-03-11T14:55:43.081566Z","iopub.status.idle":"2024-03-11T14:55:43.396598Z","shell.execute_reply.started":"2024-03-11T14:55:43.081499Z","shell.execute_reply":"2024-03-11T14:55:43.395206Z"},"trusted":true},"execution_count":null,"outputs":[]}]}